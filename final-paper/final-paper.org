#+TITLE: OAK
#+SUBTITLE: 
#+AUTHOR: Cedric Sirianni, Mithi Jethwa, Lachlan Kermode
#+OPTIONS: toc:nil
#+LATEX_CLASS: acmart
#+LATEX_CLASS_OPTIONS: [sigconf]
#+LATEX_HEADER: \usepackage{hyperref}
#+LATEX_HEADER: \usepackage{adjustbox}
#+BIBLIOGRAPHY: ./references.bib 

# NB: This bib file is derived from the following Zotero library: https://www.zotero.org/groups/5686187/vector-databases/library

#+LATEX: \hypersetup{linkcolor=blue}


* Abstract
Vector databases are growing in popularity as they become widely used in similarity search and RAG (Retrieval Augmented Generation) systems as part of ML workloads.
Recent work in ACORN helps improve the feasibility of /hybrid search/ by providing a performant and predicate-agnostic index built on Hierarchical Navigable Small Worlds (HNSW), a state-of-the-art graph based index for approximate nearest neighbor search (ANNS).
This paper presents OAK, a system that improves upon ACORN's performance for certain query loads by routing to subgraph indexes when there are gains to be had.
To evaluate OAK, we compare OAK to ACORN ... =TODO=. 
We show that OAK achieves improved performance ... =TODO=. 
Our code is available on Github [cite:@kermodeBreezykermoOak2024].

* Introduction
In recent years, vector similarity search has become a staple method in the arsenal of engineering tools for ML applications.
Recommendation algorithms at companies like Netflix, Spotify, and TikTok use vector embeddings to represent user profiles and platform content.
In these applications, approximate nearest neighbor search (ANNS) is the method used for performant semantic similarity search.
Because machine learning inherently clusters/groups data, ANNS is a way to coalesce inherently unstructured data for specific operations, making it an essential primitive in big data operations.

This growth is in no small part due to the success of machine-learning vectorization methods such as BERT [cite:@devlinBertPretrainingDeep2018] which generate embeddings that seem to preserve something semantic about the original document, a result that turns vector similarity search into a powerful heuristic for /semantic/ search.  
The generality and potential of vector similarity search in pools of /unstructured/ data is limited, however, by the relative complexity of its interoperation with more traditional /structured/ search methods in databases, whereby databases can deliver better performance and correctness characteristics thanks to decades of research in SQL and SQL-like query optimization. 

One increasingly important use-case for ANNS, for example, is retrieval-augmented generation (RAG), which helps improve the accuracy and relevance of LLM outputs by including additional vector embeddings in user prompts.
In RAG it is often desirable to perform ANNS with predicates that help to narrow down the relevance of results in this task, for example finding similar prompts from the same user, or from users in the same organization.
Creating separate vector databases for predicates manually and maintaining routing strategies among them is unwieldy and suboptimal in terms of space, as many there may be significant overlap between many of the indexes, and deciding which predicate subgraphs to build manually requires engineering effort and effective observability instrumentation on the part of the vector database client.

Executing *hybrid search*, i.e. vector similarity search results are additionally constrained by unbounded and arbitrary predicates over the set of all possible vectors in a vector database, is therefore an important problem in vector databases, as it relieves the database client of managing this complexity.  
The performance profile of ANNS becomes more complex when introducing such predicate filtering, however, as will be discussed in Section @@latex:\ref{sec:motivation}@@.
One recent approach, ACORN [cite:@patelACORNPerformantPredicateAgnostic2024], proposes an architecture for a /predicate-agnostic/ ANNS index that addresses some of these performance complexities.
# Efficient ANNS is a challenging problem when considering multi-million or billion scale datasets.
# Both NeurIPS'21 [cite:https://big-ann-benchmarks.com/neurips21.html]and NeurIPS'23 [cite:https://big-ann-benchmarks.com/neurips23.html] hosted a competition for billion-scale indexing data structures and search algorithms, showcasing a wide range of solutions that improved search accuracy and efficiency.
# For example, customers on an e-commerce site may want to search for t-shirts similar to a reference image, while filtering on price. 
# To support such functionality, applications must implement /hybrid search/, i.e., similarity search queries containing a one or more structured predicates.
# Implementations must be *performant*, retrieving results with high throughput/low latency and also *accurate*, retrieving results that are sufficiently similar to the provided query.

# Several strategies exist to address these challenges with varying degrees of success, including pre-filtering, post-filtering, and specialized indices.

In this paper, we present *OAK* (Opportunistic ANNS K-Subgraphs), a system that applies ACORN's principle of predicate-agnostic hybrid vector similarity search in a system that offers better performance for certain query loads by maintaining indexes of predicate subgraphs in addition to a base index and intelligently routing to these indexes when there is significant overlap between such an index and a query predicate.

* Research Problem/Motivation
#+LABEL: sec:motivation

We now discuss the existing predicate filtering strategies.

/Pre-filtering/ first finds all vectors that satisfy a given predicate and then performs a similarity search on the remaining vectors.
This approach performs poorly when using medium to high selectivity predicates on large datasets.

/Post-filtering/ first performs a similarity search on the dataset, then filters results that do not match the given predicate. 
Since vectors with the greatest similarity may not satisfy the predicate, this approach sometimes requires searching repeatedly with increasingly large search spaces (top-1k, top-10k, etc.), incurring large amounts of overhead.

/Specialized indices/ such as Filtered-DiskANN [cite:] use predicates during index construction to eliminate the need for pre- or post-filtering.
However, these indices restrict predicate set cardinalities to about 1,000 and only support equality predicates.

Recently, ACORN [cite:] has proposed a /predicate-agnostic/ index which supports unbounded and arbitrary predicates.
The results are impressive but still fall short of an /oracle partition index/ (Figure 1). 
# TODO: Include figure from presentation.
Given some search predicate $p$ and dataset $X$, an oracle partition index is an index on $X_p$. 
An oracle partition index is more performant compared to a base ACORN index because the search space is guaranteed to contain only vectors that satisfy the predicate, and thus no predicate comparison must occur during the search itself.
The reason ACORN provides a /predicate-agnostic/ index is because in many systems, it is infeasible to construct an index for every possible predicate, and thus a general-purpose index performs well across a diverse array of queries.

However, access patterns are sometimes not uniformly distributed.
Consider, for example, queries about football teams during Superbowl or states during election night.
In certain scenarios, a general-purpose predicate-agnostic index can be supplemented by carefully chosen supplemental indices constructed using frequently occurring predicates.
This is the goal of OAK.

* Background and Related Work

The underlying data structure of both ACORN and OAK is Hierarchical Navigable Small Worlds (HNSW)[cite:https://arxiv.org/abs/1603.09320], a hierarchical, tree-link structure where each node of the tree represents a set of vectors.
More specifically, it is a /proximity graph/, in which two vertices are linked based on proximity.
Proximity is usually computed using Euclidean distance, though other similarity metrics exist (e.g. cosine similarity).

ACORN modifies the HNSW construction algorithm to use neighbor expansion, creating a denser graph.
While HNSW collects $M$ approximate nearest neighbors as candidate edges for each node in the index, ACORN collects $M \dot \gamma$ approximate nearest neighbors as candidate edges per node.
The intuition is that given enough redundant nodes, the search space is sufficiently large, even when filtering based on the predicate during search.

This is not always the case, though. 
If the predicate selectivity falls below a minimum specified threshold, ACORN resorts to pre-filtering and brute force search, favoring recall over performance.
This may explain the difference in throughput between ACORN-$\gamma$ and the opportunistic index in Figure 1.

* Main Design

The central premise of OAK is to route queries with high-frequency predicates to an /opportunistic index/ constructed using the same predicate.
When OAK receives a query $q$ with predicate $p$, sending to an opportunistic index is (1) potentially more performant (if the base index is larger than the opportunistic index) but (2) potentially less accurate (if the opportunistic index does not contain all vectors that match $p$).
We factor this performance-accuracy tradeoff into our query routing strategy.

* Implementation 

OAK is built in approximately 700 lines of Rust.
We encountered three main engineering challenges, which we now discuss in sections.

** Bindings

ACORN is implemented in C++, so writing OAK in Rust required a foreign function interface (FFI).
We chose bindgen [cite:] to automatically generate Rust FFI bindings to ACORN, but the task required a substantial engineering effort.
We discovered a bug in the ACORN compilation directions that resulted in PR [cite:https://github.com/guestrin-lab/ACORN/pull/7], the FFI wrappers introduced lifetime issues when dereferencing a unique pointer, and the functionality of the ACORN ~search~ function had to be largely reverse-engineered due to a lack of documentation.

** Predicate Filtering

To programmatically represent predicates, we introduce the `PredicateQuery` struct which contains a predicate operator (e.g. equality) and an operand. 
This `PredicateQuery` is used to generate a bit mask over the set of vectors and is designed to be extensible for any arbitrary predicate.
For each vector, if the predicate is true (e.g. year == 2024), the corresponding bit mask element is set to 1.
The ACORN ~search~ function accepts a ~filter_id_map~ bit mask that is used to filter vectors that do not satisfy the predicate during search.

** Query Routing

* Evaluation

* Future Work

OAK has many opportunities for future work.

*Dynamic index construction*. 
Right now, OAK constructs indices only once and before queries are dispatched.
In a production system, it may be advantageous to construct indices while queries are received to increase throughput.
The overhead incurred by index construction could be measured with respect to the time to index (TTI), the size of the index, and the compute/memory resources required to construct the index.

*Index type*.
OAK uses ACORN for opportunistic indices primarily because writing bindings to additional indices is unnecessary for a proof-of-concept.
However, given the bounded and well-defined nature of the opportunistic index type, a /specialized index/ may yield better performance.
For example, Qdrant [cite:https://qdrant.tech/articles/filtrable-hnsw/] has proposed denser HNSW graph by knowledge of the search predicates to add additional edges.
While this is ill-suited for ACORN's goal to be predicate-agnostic, the principle idea of opportunistic indices is /predicate-knowledge/, and thus we can leverage the known predicate to construct a better index.

*Distribution*.
The system design of OAK is also easily transferrable to a distributed context. 
We could construct and/or host indices on different nodes, as network communication costs are dominated by the ANNS latency. [cite:]
This would help remove the bottleneck of commodity hardware when hosting multiple indices and enable horizontal scaling and load balancing during bursty workloads.

* Logistics

* Bibliography
